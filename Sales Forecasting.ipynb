{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe9fbdd",
   "metadata": {},
   "source": [
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79074359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m ipykernel install --user --name=\"Sales Forecasting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5812ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "np.__version__, tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5066b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "#import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from keras.optimizers import Adam .\n",
    "from tensorflow.keras.optimizers import Adam # - Works\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da52264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall xlrd\n",
    "\n",
    "#!pip install openpyxl\n",
    "# !pip install xlrd==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b093dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Data Set.xlsx', engine='openpyxl') #reading data excel file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53473044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7756d33e",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b76ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.loc[17:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb45e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.reset_index(inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8828216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop('index',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e72dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.loc[0]\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(df.index[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7477d0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop('index',axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa67bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ffill(inplace=True)\n",
    "df.head(110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~df['Date'].str.contains(\"Total\")]\n",
    "df.head(110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c89881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~df['Date'].str.contains(\"Total\")]\n",
    "df.head(107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['Date','Item Name',\"Qty Total (Cup)\"]]\n",
    "df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eaf320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7212d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df[\"Date\"]=df['Date'].dt.strftime('%d/%m/%Y')\n",
    "sum_df = df.groupby(['Date','Item Name']).agg({'Qty Total (Cup)': 'sum'})\n",
    "sum_df=sum_df.reset_index()\n",
    "sum_df[\"Date\"] = pd.to_datetime(sum_df[\"Date\"],infer_datetime_format=True)\n",
    "sum_df.sort_values(by=['Date'], inplace=True, ascending=True)\n",
    "sum_df[\"Date\"]=sum_df['Date'].dt.strftime('%Y-%m-%d')\n",
    "sum_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = sum_df.reset_index(drop=True)\n",
    "sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6fc317",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = sum_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba86c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.groupby(['Item Name']).agg({'Qty Total (Cup)': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff26f71",
   "metadata": {},
   "source": [
    "# Sales record of Brown Sugar Milk Tea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d9085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sum_df[sum_df['Item Name'].str.contains(\"Brown Sugar Milk Tea\")]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7fd55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'Date':'date','Qty Total (Cup)':'sales'}, inplace = True)\n",
    "df_sales = data.copy()\n",
    "df_sales = df_sales[['date','sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c544f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.reset_index(inplace=True, drop=True)\n",
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2767290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['date'] = pd.to_datetime(df_sales['date']) \n",
    "df_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3155ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = df_sales.iloc[17:-21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.reset_index(inplace=True, drop=True)\n",
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cca6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = df_sales.drop_duplicates('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88759c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['sales'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04319161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['sales'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df_sales['sales'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## handling outliers\n",
    "outliers = []\n",
    "def detect_outliers_iqr(data):\n",
    "    data = sorted(data)\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    # print(q1, q3)\n",
    "    IQR = q3-q1\n",
    "    lwr_bound = q1-(1.5*IQR)\n",
    "    upr_bound = q3+(1.5*IQR)\n",
    "    # print(lwr_bound, upr_bound)\n",
    "    for i in data: \n",
    "        if (i<lwr_bound or i>upr_bound):\n",
    "            outliers.append(i)\n",
    "    return outliers# Driver code\n",
    "sample_outliers = detect_outliers_iqr(df_sales['sales'])\n",
    "print(\"Outliers from IQR method: \", sample_outliers)\n",
    "\n",
    "median = np.median(df_sales['sales'])# Replace with median\n",
    "sales = np.array(list(df_sales['sales']))\n",
    "#print(len(sales))\n",
    "#c = None\n",
    "for i in sample_outliers:\n",
    "    df_sales['sales'] = np.where(df_sales['sales']==i, int(median), df_sales['sales'])\n",
    "    #print(i)\n",
    "    #print(c)\n",
    "    #print('-----')\n",
    "print(\"Sample: \", median)\n",
    "print(\"New array: \", df_sales['sales'])\n",
    "#print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed059a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df_sales['sales'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1acdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['sales'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing For Stationarity\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ho: It is non stationary\n",
    "#H1: It is stationary\n",
    "def adfuller_test(sales):\n",
    "    result=adfuller(sales)\n",
    "    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
    "    for value,label in zip(result,labels):\n",
    "        print(label+' : '+str(value) )\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data has no unit root and is stationary\")\n",
    "    else:\n",
    "        print(\"weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59314bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller_test(df_sales['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe to model the difference\n",
    "# df_diff = df_sales.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c659e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sales['Seasonal First Difference']=df_sales['sales'] - df_sales['sales'].shift(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2931e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Again test dickey fuller test\n",
    "# adfuller_test(df_sales['Seasonal First Difference'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec06532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sales['Seasonal First Difference'].plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e2d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.index = df_sales['date']\n",
    "df_sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f24460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.drop('date', axis=1, inplace=True)\n",
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9263660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = df_sales.fillna(method='bfill').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "sales = df_sales.sales.asfreq('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cab563",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales.fillna(method='bfill').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49484d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = seasonal_decompose(sales)\n",
    "results.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90468ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6931b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_sales[:-30]\n",
    "test = df_sales[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d696d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train)\n",
    "scaled_train = scaler.transform(train)\n",
    "scaled_test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca46573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220caf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "n_input = 7\n",
    "n_features = 1\n",
    "generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203782d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = generator[0]\n",
    "print(f'Given the Array: \\n{X.flatten()}')\n",
    "print(f'Predict this y: \\n {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d0852",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4620ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32a6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_input, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233bd0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(generator,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bfe4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_epoch = model.history.history['loss']\n",
    "plt.plot(range(len(loss_per_epoch)),loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9effd830",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_batch = scaled_train[-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b71775",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_batch = last_train_batch.reshape((1, n_input, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b87a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(last_train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87075b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0838855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales[-7:].to_csv('examplers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6588b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d8c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = 'scaler.sav'\n",
    "joblib.dump(scaler, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d7cd1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b1b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tensorflow.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('examplers.csv')\n",
    "test_df.set_index('date', inplace=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5284011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled_train = scaler.transform(train)\n",
    "scaler_load = joblib.load('scaler.sav')\n",
    "scaled_test = scaler_load.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321123b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c44143",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "\n",
    "first_eval_batch = scaled_test\n",
    "current_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    \n",
    "    # get the prediction value for the first batch\n",
    "    current_pred = model.predict(current_batch)[0]\n",
    "    \n",
    "    # append the prediction into the array\n",
    "    test_predictions.append(current_pred) \n",
    "    \n",
    "    # use the prediction to update the batch and remove the first value\n",
    "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25880a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions = scaler_load.inverse_transform(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c20f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4884a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "ind = test_df.tail(1).index\n",
    "date_indices = pd.date_range(ind[0], periods=8)\n",
    "exemplers_df = pd.DataFrame({'sales': list(np.round(true_predictions.flatten(), 2))}, index=date_indices[1:])\n",
    "exemplers_df.index.name = 'date'\n",
    "print(exemplers_df)\n",
    "exemplers_df.to_csv('examplers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb15941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6291d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Predictions'] = true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame(test_df['Predictions'])\n",
    "#df_.to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e94c38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc11b798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d85448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.plot(figsize=(14,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54468f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc460b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e5fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d33a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92451b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "autocorrelation_plot(df_sales['sales'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = plot_acf(df_sales['Seasonal First Difference'].iloc[200:],lags=40,ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = plot_pacf(df_sales['Seasonal First Difference'].iloc[200:],lags=40,ax=ax2)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e1a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For non-seasonal data\n",
    "#p=1, d=1, q=0 or 1\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ba978",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ARIMA(df_sales['sales'],order=(1,1,0))\n",
    "model_fit=model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d222a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaadb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['forecast']=model_fit.predict(start=90,end=300,dynamic=True)\n",
    "df_sales[['sales','forecast']].plot(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8157b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "model=sm.tsa.statespace.SARIMAX(df_sales['sales'],order=(1, 1, 1),seasonal_order=(1,1,1,200))\n",
    "results=model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d068d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales['forecast']=results.predict(start=201,end=270,dynamic=True)\n",
    "df_sales[['sales','forecast']].plot(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e1ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c59f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5234db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add previous sales to the next row\n",
    "df_diff['prev_sales'] = df_diff['sales'].shift(1)\n",
    "#drop the null values and calculate the difference\n",
    "df_diff = df_diff.dropna()\n",
    "\n",
    "df_diff['diff'] = (df_diff['sales'] - df_diff['prev_sales'])\n",
    "\n",
    "#create new dataframe from transformation from time series to supervised\n",
    "df_supervised = df_diff.drop(['prev_sales'],axis=1)\n",
    "df_supervised= df_supervised.append(pd.DataFrame({'date': pd.date_range(start=df_supervised.date.iloc[-1], periods=6, freq='D', closed='right')}))\n",
    "#adding lags\n",
    "for inc in range(1,13):\n",
    "    field_name = 'lag_' + str(inc)\n",
    "    df_supervised[field_name] = df_supervised['diff'].shift(inc)\n",
    "    \n",
    "#drop null values\n",
    "df_supervised = df_supervised.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e81382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraDates=pd.DataFrame({'date': pd.date_range(start=df_supervised.date.iloc[-1], periods=6, freq='d', closed='right')})\n",
    "fdf=df_supervised.append(extraDates)\n",
    "fdf['date'] = pd.to_datetime(fdf['date'], errors='coerce')\n",
    "fdf[\"date\"]=fdf['date'].dt.strftime('%Y-%m-%d')\n",
    "fdf=fdf.reset_index()\n",
    "fdf = fdf.drop(['index'],axis=1)\n",
    "\n",
    "fdf.tail(20)\n",
    "fdf=fdf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7042ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statsmodels.formula.api\n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "# Define the regression formula\n",
    "model = smf.ols(formula='diff ~ lag_1', data=df_supervised)\n",
    "\n",
    "# Fit the regression\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Extract the adjusted r-squared\n",
    "regression_adj_rsq = model_fit.rsquared_adj\n",
    "print(regression_adj_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8663254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import statsmodels.formula.api\n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "# Define the regression formula\n",
    "model = smf.ols(formula='diff ~ lag_1 + lag_2 + lag_3 + lag_4 + lag_5', data=df_supervised)\n",
    "\n",
    "# Fit the regression\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Extract the adjusted r-squared\n",
    "regression_adj_rsq = model_fit.rsquared_adj\n",
    "print(regression_adj_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statsmodels.formula.api\n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "# Define the regression formula\n",
    "model = smf.ols(formula='diff ~ lag_1 + lag_2 + lag_3 + lag_4 + lag_5 + lag_6 + lag_7 + lag_8 + lag_9 + lag_10 + lag_11 + lag_12', data=df_supervised)\n",
    "\n",
    "# Fit the regression\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Extract the adjusted r-squared\n",
    "regression_adj_rsq = model_fit.rsquared_adj\n",
    "print(regression_adj_rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4047cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import MinMaxScaler and create a new dataframe for LSTM model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df_model = fdf.drop(['sales','date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fa16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0477d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test set\n",
    "train_set, test_set = df_model[0:-50].values, df_model[-50:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply Min Max Scaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(train_set)\n",
    "# reshape training set\n",
    "train_set = train_set.reshape(train_set.shape[0], train_set.shape[1])\n",
    "train_set_scaled = scaler.transform(train_set)\n",
    "\n",
    "# reshape test set\n",
    "test_set = test_set.reshape(test_set.shape[0], test_set.shape[1])\n",
    "test_set_scaled = scaler.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dec813",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d264d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df3270",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1]\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f1da25",
   "metadata": {},
   "source": [
    "# Training LSTM  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6868a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), stateful=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, validation_data=(X_test, y_test),verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "model=loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e750ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test,batch_size=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape y_pred\n",
    "y_pred = y_pred.reshape(y_pred.shape[0], 1, y_pred.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f952618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rebuild test set for inverse transform\n",
    "pred_test_set = []\n",
    "for index in range(0,len(y_pred)):\n",
    "    print(np.concatenate([y_pred[index],X_test[index]],axis=1))\n",
    "    pred_test_set.append(np.concatenate([y_pred[index],X_test[index]],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape pred_test_set\n",
    "pred_test_set = np.array(pred_test_set)\n",
    "pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbecfca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse transform\n",
    "pred_test_set_inverted = scaler.inverse_transform(pred_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe that shows the predicted sales\n",
    "result_list = []\n",
    "sales_dates = list(df_sales[-51:].date)\n",
    "act_sales = list(df_sales[-51:].sales)\n",
    "# pred_test_set_inverted[index][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(0,len(pred_test_set_inverted)):\n",
    "    result_dict = {}\n",
    "    print(index)\n",
    "    result_dict['pred_value'] = int(pred_test_set_inverted[index][0] + act_sales[index])\n",
    "    result_dict['date'] = sales_dates[index+1]\n",
    "    result_list.append(result_dict)\n",
    "df_result = pd.DataFrame(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b80ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with actual sales dataframe\n",
    "df_sales_pred = pd.merge(df_sales,df_result,on='date',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_pred.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1129129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(20, 10), dpi=80)\n",
    "plt.plot(df_sales_pred['date'], df_sales_pred['sales'], label = \"actual\")\n",
    "plt.plot(df_sales_pred['date'], df_sales_pred['pred_value'], label = \"predicted\")\n",
    "# plt.plot(x, y, label = \"line 1\")\n",
    "# plt.plot(y, x, label = \"line 2\")\n",
    "plt.xlabel(\"Dates\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11157e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sales-Forecasting",
   "language": "python",
   "name": "sales-forecasting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
